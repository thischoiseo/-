{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDYe1GYAGvzG"
      },
      "outputs": [],
      "source": [
        "!pip show protobuf\n",
        "\n",
        "!pip uninstall tensorflow tensorflow-metadata protobuf -y\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow --use-deprecated=legacy-resolver\n",
        "\n",
        "!pip install langchain_community\n",
        "!pip install langchain_text_splitters\n",
        "!pip install langchain_openai\n",
        "!pip install langchain_huggingface\n",
        "!pip install chromadb\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "from typing import List\n",
        "from langchain.schema import Document  # Import Document if needed\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader('/content/drive/MyDrive/Intro.txt')\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "QO2Mh-_xHJ14"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "ujEzbrYbIQD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=150,\n",
        "    chunk_overlap=50,\n",
        "    encoding_name='cl100k_base'\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_text(data[0].page_content)"
      ],
      "metadata": {
        "id": "ZhDN9bW3J9DA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "id": "vNsBFDmGJ-3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = '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' #본인의 Hugging Face token 입력"
      ],
      "metadata": {
        "id": "aqUvtOwvKAOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model = HuggingFaceEmbeddings(\n",
        "        model_name='jhgan/ko-sroberta-nli',\n",
        "        model_kwargs={'device':'cpu'},\n",
        "        encode_kwargs={'normalize_embeddings':True}\n",
        "    )"
      ],
      "metadata": {
        "id": "Rr4Gs3f3KDYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(texts[0])\n",
        "embeddings_model.embed_query(texts[0])[:3]"
      ],
      "metadata": {
        "id": "20d4hNF7KXo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorized size\n",
        "len(embeddings_model.embed_query(texts[0]))"
      ],
      "metadata": {
        "id": "lt1P4M-5LE3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = Chroma.from_texts(\n",
        "    texts,\n",
        "    embeddings_model,\n",
        "    collection_name = 'history',\n",
        "    persist_directory = './db/chromadb',\n",
        "    collection_metadata = {'hnsw:space': 'cosine'}, # l2 is the default\n",
        ")\n",
        "\n",
        "db"
      ],
      "metadata": {
        "id": "1UFMFjQELIvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = '디지털경영전공은 무엇인가요?'\n",
        "docs = db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "3q9wgTQDLKCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "n8L-DMXpLOeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = '데이터분석과 빅데이터는 무슨 상관인가요'\n",
        "docs = db.similarity_search(query)\n",
        "print(docs[0].page_content)"
      ],
      "metadata": {
        "id": "WR8QTn6CLQMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the online retail dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/amazon.csv')\n",
        "df = data[:100].copy()\n",
        "df.dropna(subset=['rating_count'], inplace=True)\n",
        "\n",
        "df['sub_category'] = df['category'].astype(str).str.split('|').str[-1]\n",
        "df['main_category'] = df['category'].astype(str).str.split('|').str[0]"
      ],
      "metadata": {
        "id": "KboGTFjDLR16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "HhC6aY99LZA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy()\n",
        "df1['product_name'] = df1['product_name'].str.lower()\n",
        "df1 = df1.drop_duplicates(subset=['product_name'])"
      ],
      "metadata": {
        "id": "rKy5BuBFMVqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df1.shape)"
      ],
      "metadata": {
        "id": "pBw-m_0QMa2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['product_name'][0]"
      ],
      "metadata": {
        "id": "vzQJEWYbMcjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1['about_product']"
      ],
      "metadata": {
        "id": "ZoLzV_lOMeUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df1[['product_id','product_name', 'about_product','main_category','sub_category', 'actual_price','discount_percentage','rating','rating_count' ]]"
      ],
      "metadata": {
        "id": "d8r5Fx4jMfY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "metadata": {
        "id": "rsEWcnA4MkCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('/content/drive/MyDrive/amazon_rag.csv', index=False)"
      ],
      "metadata": {
        "id": "uoHKOOZWMlH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "from langchain.embeddings.huggingface_hub import HuggingFaceHubEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.schema.document import Document\n",
        "\n",
        "\n",
        "# This will expose your Langchain api token as an environment variable\n",
        "load_dotenv()\n",
        "\n",
        "# def read_csv(file_path: str, source_column: str = \"about_product\") -> List[Document]:\n",
        "def read_csv(file_path: str, source_column: str = \"product_name\") -> List[Document]:\n",
        "    \"\"\"Reads a CSV file and returns a list of Documents.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the CSV file to read.\n",
        "        source_column (str, optional): The name of the column in the CSV file that contains the text data. Defaults to \"Description\".\n",
        "\n",
        "    Returns:\n",
        "        List[Document]: A list of Documents, where each Document contains the text data from the corresponding row in the CSV file.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: If the CSV file does not exist.\n",
        "        IOError: If there is an error reading the CSV file.\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File does not exist: {file_path}\")\n",
        "\n",
        "    loader = CSVLoader(file_path=file_path, source_column=source_column)\n",
        "    data = loader.load()\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "NSxOViimMqjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = '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' #본인의 Hugging Face token 입력"
      ],
      "metadata": {
        "id": "cSoMJX4xM3hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "#reference: https://python.langchain.com/docs/integrations/providers/huggingface/#huggingfaceembeddings\n",
        "# model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
        "model_name = 'jhgan/ko-sroberta-nli'\n",
        "\n",
        "# Function to load embeddings model\n",
        "def load_embeddings_model(model_name: str) -> HuggingFaceEmbeddings:\n",
        "    \"\"\"Loads a Hugging Face Transformer model and returns an Embeddings object.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): The name of the Hugging Face Transformer model to load.\n",
        "\n",
        "    Returns:\n",
        "        HuggingFaceEmbeddings: An Embeddings object that can be used to encode text into embeddings.\n",
        "    \"\"\"\n",
        "    embedding_function = HuggingFaceEmbeddings(\n",
        "        model_name=model_name,\n",
        "        # huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
        "        model_kwargs={'device':'cpu'},\n",
        "        encode_kwargs={'normalize_embeddings':True}\n",
        "    )\n",
        "    return embedding_function"
      ],
      "metadata": {
        "id": "pdZRXrtrM8xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the embeddings\n",
        "\n",
        "# model_name = \"intfloat/multilingual-e5-large-instruct\"\n",
        "model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
        "# model_name = 'jhgan/ko-sroberta-nli'\n",
        "embeddings = load_embeddings_model(model_name)\n",
        "\n",
        "# Test embedding a query\n",
        "text = \"This is a test document.\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "print(query_result[:3])"
      ],
      "metadata": {
        "id": "sKcTuW3tM-UY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_documents(data: List[Document], embedding_function: HuggingFaceEmbeddings) -> Chroma:\n",
        "    \"\"\"Vectorizes a list of Documents using a Hugging Face Transformer model.\n",
        "\n",
        "    Args:\n",
        "        data (List[Document]): A list of Documents to vectorize.\n",
        "        embedding_function (HuggingFaceEmbeddings): An Embeddings object that can be used to encode text into embeddings.\n",
        "\n",
        "    Returns:\n",
        "        Chroma: A Chroma object that contains the vectorized documents.\n",
        "    \"\"\"\n",
        "\n",
        "    ## Chroma, as a vector database, cosine similarity by default for searches.\n",
        "    db = Chroma.from_documents(data, embedding=embedding_function,\n",
        "                            #    collection_metadata={\"hnsw:space\": \"l2\"}\n",
        "                               collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        "                               )\n",
        "    return db"
      ],
      "metadata": {
        "id": "7SJWew-hM_0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_llm():\n",
        "    \"\"\"Initializes the LLM by reading the CSV file, loading the embeddings model, and vectorizing the documents.\n",
        "\n",
        "    Returns:\n",
        "        Chroma: A Chroma object that contains the vectorized documents.\n",
        "    \"\"\"\n",
        "    # Replace 'read_csv' with the appropriate CSV reading logic\n",
        "    data = read_csv(file_path='/content/drive/MyDrive/amazon_rag.csv', source_column=\"product_name\")\n",
        "    model_name = 'sentence-transformers/all-mpnet-base-v2'\n",
        "    # model_name = 'jhgan/ko-sroberta-nli'\n",
        "    embedding_function = load_embeddings_model(model_name)\n",
        "    db = vectorize_documents(data, embedding_function)\n",
        "    return db"
      ],
      "metadata": {
        "id": "to81i5slNP2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = init_llm()"
      ],
      "metadata": {
        "id": "FyZKe_NtNRTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Query the vector database\n",
        "query = \"iPhone USB charger and adapter\"\n",
        "found_docs = db.similarity_search_with_score(query, k=5)"
      ],
      "metadata": {
        "id": "_YmlB56PNS3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "found_docs"
      ],
      "metadata": {
        "id": "ssHvXFXBN_16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Document with Score\n",
        "document, score = found_docs[-1]\n",
        "print(document.page_content)\n",
        "print(f\"\\nScore: {score}\")"
      ],
      "metadata": {
        "id": "C_8swEQwOB0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "found_docs[-1][0].page_content"
      ],
      "metadata": {
        "id": "Vbp9nTjSOEmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get source\n",
        "found_docs[0][0].metadata['source']"
      ],
      "metadata": {
        "id": "ThlkKmXgOHhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def run_vector_search(query: str):\n",
        "#     # print(query)\n",
        "#     query_vector = db.similarity_search_with_score(query, k=5)\n",
        "#     # print(query_vector)\n",
        "#     # document, score = query_vector\n",
        "\n",
        "#     # return query_vector.metadata['source'], document.page_content, score\n",
        "#     return query_vector\n",
        "\n",
        "def run_vector_search(query: str, k = 3) -> str:\n",
        "    \"\"\"Performs a vector search and returns results in a structured format.\"\"\"\n",
        "    query_vector = db.similarity_search_with_score(query, k=k)\n",
        "\n",
        "    # Extract and structure the search results\n",
        "    results = []\n",
        "    for document, score in query_vector:\n",
        "        # Extract metadata and page content\n",
        "        metadata = document.metadata\n",
        "        page_content = {k.strip(): v.strip() for k, v in [line.split(':', 1) for line in document.page_content.split('\\n') if ':' in line]}\n",
        "\n",
        "        # Combine all data into a single dictionary\n",
        "        combined_result = {\n",
        "            \"source\": metadata.get(\"source\", \"Unknown Source\"),\n",
        "            **page_content,\n",
        "            \"score\": score\n",
        "        }\n",
        "        results.append(combined_result)\n",
        "\n",
        "    # Convert to a DataFrame\n",
        "    df_results = pd.DataFrame(results)\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "QE92ZUrYOJFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_vector_search('what is the iphone cable?')"
      ],
      "metadata": {
        "id": "O1gE9PdrOK-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "import transformers\n",
        "import torch\n",
        "\n",
        "# Load model\n",
        "# model = \"nilq/mistral-1L-tiny\"\n",
        "#huggingface-cli login\n",
        "#Reference: https://huggingface.co/docs/huggingface_hub/en/guides/cli\n",
        "\n",
        "model = \"ArliAI/Gemma-2-2B-ArliAI-RPMax-v1.1\"#'ArliAI/Mistral-Small-22B-ArliAI-RPMax-v1.1'\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model,\n",
        "    use_auth_token= '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', #본인의 Token 업데이트,\n",
        ")\n",
        "\n",
        "# pipeline\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "GFXGYfydONhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "\n",
        "hf = HuggingFacePipeline(pipeline=pipeline)"
      ],
      "metadata": {
        "id": "eIricMUkOPoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "promptTemplate_fstring = \"\"\"\n",
        "You are a customer service assistant, tasked with providing clear and concise answers based on the given context.\n",
        "Context:\n",
        "{context}\n",
        "Question:\n",
        "{query}\n",
        "Answer:\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "PWJzswr5O-Y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "print(prompt)\n",
        "chain = prompt | hf\n",
        "\n",
        "question = \"What is electroencephalography?\"\n",
        "\n",
        "print(chain.invoke({\"question\": question}))"
      ],
      "metadata": {
        "id": "fnRUt8PEPPgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Query definition\n",
        "query = \"suggest cool iPhone USB charger and adapter\"\n",
        "# query = \"what is the iphone cable?\"\n",
        "# query = \"What is the caracteristic of iPhone USB charger and adapter\"\n",
        "\n",
        "# Perform vector search\n",
        "doc_context = run_vector_search(query)\n",
        "\n",
        "# Extract relevant columns\n",
        "doc = doc_context[['product_name', 'about_product']]\n",
        "# doc = doc_context[[ 'about_product']]\n",
        "\n",
        "# print(doc)\n",
        "# Convert context to string\n",
        "context = doc.to_string(index=False)\n",
        "\n",
        "#You are an assistant in customer service. Use the following context to answer the question:\n",
        "\n",
        "# Define the prompt template\n",
        "# promptTemplate_fstring = \"\"\"\n",
        "# Context:\n",
        "# {context}\n",
        "# Question:\n",
        "# {query}\n",
        "# Answer:\n",
        "# \"\"\"\n",
        "\n",
        "promptTemplate_fstring = \"\"\"\n",
        "You are a customer service assistant, tasked with providing clear and concise answers based on the given context.\n",
        "Context:\n",
        "{context}\n",
        "Question:\n",
        "{query}\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the prompt\n",
        "prompt = PromptTemplate(\n",
        "    # input_variables=[\"query\", \"context\"],\n",
        "    template=promptTemplate_fstring,\n",
        ")\n",
        "\n",
        "# print(prompt)\n",
        "# Create the chain\n",
        "chain = LLMChain(prompt=prompt, llm=hf)\n",
        "\n",
        "# Run the chain and get the response\n",
        "response = chain.run({\"query\": query, \"context\": context})\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "id": "_0fS0c7bPP37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gPYuC9y6PUTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}